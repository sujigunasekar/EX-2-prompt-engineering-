# EX-5 Comparative Analysis of different types of Prompting patterns and explain with Various Test scenerios

# Experiment:
Test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios. 
     Analyze the quality, accuracy, and depth of the generated responses.

# Objective
To compare how different prompting patterns affect the performance of AI models in terms of quality, accuracy, and depth of responses.

# 1.Introduction to Prompting Patterns

Prompting refers to how a question or instruction is framed for an AI model. There are different types:

### a. Broad or Unstructured Prompt

Vague or open-ended.


Gives AI freedom but may lead to less focused responses.


Example: "Tell me about climate change."

### b. Basic Prompt

Clear and direct.


Focuses the AI on a specific task or question.


Example: "Explain the causes of climate change in three bullet points."


# 2.Prompting Pattern Comparison Framework

![image](https://github.com/user-attachments/assets/89c46e03-104b-4536-9f0d-c8a8fec3b359)

# 3.Test Scenarios and Results

## Scenario 1: Educational Topic

### Prompt A (Broad):
"Explain photosynthesis."

### Response Quality:

-Detailed but lengthy


-Includes processes, formulas, and examples


-Sometimes includes unnecessary info

### Prompt B (Basic):

"Explain the process of photosynthesis in 3 steps suitable for 6th-grade students."

### Response Quality:

-More focused and age-appropriate


-Easier to follow


-Higher accuracy for the target audience



## Scenario 2: Creative Writing

### Prompt A (Broad):

"Write a story about a robot."

### Response Quality:

-Highly imaginative


-Varies with creativity


-Lacks clear structure sometimes

### Prompt B (Basic):

"Write a 3-paragraph story about a robot who learns to feel emotions."

### Response Quality:

-More structured


-Focuses on emotional growth


-Better character development


## Scenario 3: Technical Explanation

### Prompt A (Broad):

"Tell me about machine learning."

### Response Quality:

-General explanation


-Mix of definitions and applications


-May miss out on key concepts

### Prompt B (Basic):

"Explain supervised and unsupervised learning in machine learning with one example each."

### Response Quality:

-Targeted response


-Accurate examples


-More useful for academic understanding


### Scenario 4: Opinion-Based Prompt

### Prompt A (Broad):

"What do you think of online education?"

### Response Quality:

-Balanced pros and cons


-Variable depth depending on model


-Can become too general

### Prompt B (Basic):

"List 2 benefits and 2 drawbacks of online education for university students."

### Response Quality:

-Straightforward, clear points


-Easy to compare and analyze


-More relevant for discussions




# 4. Summary of Findings


![image](https://github.com/user-attachments/assets/36c87368-4c9e-4693-87bc-f356b1c28cee)


# 5. Conclusion

-Broad Prompts are useful for creative and exploratory responses, but may lack structure.


-Basic Prompts produce more accurate and focused outputs, suitable for technical, educational, or professional contexts.


-The choice of prompting pattern should depend on the goal of the interactionâ€”whether creative generation or informative clarity is the priority.


# RESULT
A comparative analysis highlighting the importance of prompt refinement for improving AI-generated responses.
